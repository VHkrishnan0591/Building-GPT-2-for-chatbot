{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14aed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b3f59ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, dim_model, num_heads, bias, model_dropout):\n",
    "        super().__init__()\n",
    "        self.dim_model = dim_model\n",
    "        self.bias = bias\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim_model // num_heads\n",
    "        self.weights_query = torch.nn.Linear(self.dim_model, self.dim_model, bias=self.bias)\n",
    "        self.weights_value = torch.nn.Linear(self.dim_model, self.dim_model, bias=self.bias)\n",
    "        self.weights_key = torch.nn.Linear(self.dim_model, self.dim_model, bias=self.bias)\n",
    "        self.dropout = torch.nn.Dropout(model_dropout)\n",
    "    def forward(self,inputs):\n",
    "        query = self.weights_query(inputs)\n",
    "        key = self.weights_key(inputs)\n",
    "        value = self.weights_value(inputs)\n",
    "        query =  torch.reshape(query,(inputs.shape[0], inputs.shape[1], self.num_heads,self.head_dim))\n",
    "        key =  torch.reshape(key,(inputs.shape[0], inputs.shape[1], self.num_heads,self.head_dim))\n",
    "        value = torch.reshape(value,(inputs.shape[0], inputs.shape[1], self.num_heads,self.head_dim))\n",
    "        query = query.transpose(1,2)\n",
    "        key = key.transpose(1,2)\n",
    "        value = value.transpose(1,2)\n",
    "        multi_head_attention_scores = torch.matmul(query, key.transpose(2,3))\n",
    "        mask = torch.triu(torch.ones(multi_head_attention_scores.shape),diagonal=1) ==1\n",
    "        result =  multi_head_attention_scores.masked_fill(mask==True, -torch.inf)\n",
    "        multi_head_attn_weights = torch.softmax(result / key.shape[-1]**0.5, dim=-1)\n",
    "        dropout = torch.nn.Dropout(0.5)\n",
    "        multi_head_attn_weights = dropout(multi_head_attn_weights)\n",
    "        multi_head_context_vectors = torch.matmul(multi_head_attn_weights,value).transpose(1,2)\n",
    "        multi_head_context_vectors = torch.reshape(multi_head_context_vectors,(inputs.shape[0],inputs.shape[1],self.dim_model))\n",
    "        return multi_head_context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240de304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer_normalisation(torch.nn.Module):\n",
    "    def __init__(self, dim_model):\n",
    "        super().__init__()\n",
    "        self.scale = torch.nn.Parameter(torch.ones(dim_model))\n",
    "        self.shift = torch.nn.Parameter(torch.zeros(dim_model))\n",
    "        self.eps = 1e-5\n",
    "    def forward(self, inputs):\n",
    "        mean = inputs.mean( dim =-1, keepdim=True)\n",
    "        var = inputs.var( dim =-1, keepdim=True)\n",
    "        normalized_inputs = (inputs - mean) / torch.sqrt(var + self.eps)\n",
    "        normalized_inputs = self.scale * normalized_inputs + self.shift\n",
    "        return normalized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7fcdbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeLU(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "     super().__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "       return 0.5 * inputs * (1 + torch.tanh(torch.sqrt(torch.tensor(2 / math.pi)) * (inputs + 0.044715 * torch.pow(inputs, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6fc39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class feed_forward(torch.nn.Module):\n",
    "    def __init__(self,dim_model):\n",
    "        super().__init__()\n",
    "        self.layer = torch.nn.Sequential(torch.nn.Linear(dim_model,4*dim_model),GeLU(),\n",
    "                                         torch.nn.Linear(4*dim_model,dim_model))\n",
    "    def forward(self, inputs):\n",
    "        return self.layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae36063",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, dim_model, num_heads, model_dropout):\n",
    "        super().__init__()\n",
    "        self.layer_norm = layer_normalisation(dim_model)\n",
    "        self.layer_norm2 = layer_normalisation(dim_model)\n",
    "        self.attention = MultiHeadAttention(dim_model, num_heads, False, model_dropout)\n",
    "        self.feed_forward = feed_forward(dim_model)\n",
    "        self.dropout = torch.nn.Dropout(model_dropout)\n",
    "    def forward(self, inputs):\n",
    "        shortcut_connection = inputs\n",
    "        layer_norm_output = self.layer_norm(inputs)\n",
    "        attention_output = self.attention(layer_norm_output)\n",
    "        attention_output = self.dropout(attention_output)\n",
    "        attention_output += shortcut_connection\n",
    "        shortcut_connection = attention_output\n",
    "        layer_norm_output2 = self.layer_norm2(attention_output)\n",
    "        feed_forward_output = self.feed_forward(layer_norm_output2)\n",
    "        feed_forward_output = self.dropout(feed_forward_output)\n",
    "        feed_forward_output += shortcut_connection\n",
    "        return feed_forward_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acd2b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gpt2_architecture(torch.nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.token_embedding = torch.nn.Embedding(config[\"vocab_size\"],config[\"emb_dim\"])\n",
    "        self.positional_embedding = torch.nn.Embedding(config['context_length'],config[\"emb_dim\"])\n",
    "        self.dropout = torch.nn.Dropout(config['drop_rate'])\n",
    "        self.transformer = torch.nn.Sequential(*[Transformer(config['emb_dim'],config['n_heads'],config['drop_rate']) for i in range(config['n_layers'])])\n",
    "        self.final_layer_norm = layer_normalisation(config['emb_dim'])\n",
    "        self.output_layer = torch.nn.Linear(config[\"emb_dim\"],config[\"vocab_size\"])\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.token_embedding(inputs)\n",
    "        x = x + self.positional_embedding(torch.arange(inputs.shape[-1]))\n",
    "        x = self.dropout(x)\n",
    "        x = self.transformer(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "099c3c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "inputs = torch.LongTensor([[6109, 3626, 6100,  345],\n",
    "        [6109, 1110, 6622,  257]])\n",
    "torch.manual_seed(123)\n",
    "model = gpt2_architecture(GPT_CONFIG_124M)\n",
    "out = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a5a297a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1810, -0.1195, -0.5631,  ...,  0.4638, -0.9327,  0.2023],\n",
       "         [-0.9883, -0.2057, -1.1612,  ...,  1.3426, -0.9906, -0.5683],\n",
       "         [-0.3225, -0.3010,  0.1254,  ...,  0.8342, -0.9038,  0.2887],\n",
       "         [-0.8906,  0.0978,  0.0120,  ...,  0.3022, -0.4171,  0.8031]],\n",
       "\n",
       "        [[-0.2862, -0.7426, -0.8761,  ...,  0.8589, -1.0763, -0.5628],\n",
       "         [ 0.6452, -0.5032, -0.8414,  ...,  0.7574, -0.7960,  0.8602],\n",
       "         [-0.3754,  0.8685, -0.2129,  ...,  0.3230, -0.8398,  0.6426],\n",
       "         [ 0.4806,  0.5054,  0.1545,  ...,  1.0216, -1.2249,  1.7587]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae63894",
   "metadata": {},
   "source": [
    "Checking the need for softmax for generating the tokens to apply it to logit tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "895c7d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 50257])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "230c96b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([27383])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(out[0][-1]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bc7cf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27383],\n",
       "        [38152]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,-1,:]\n",
    "torch.argmax(out[:,-1,:],dim=1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f547196e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27383],\n",
       "        [38152]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.softmax(out[:,-1,:],dim=1),dim=1,keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ef5a4",
   "metadata": {},
   "source": [
    "Concludes we dont need softmax as both give the same result with or without softmax probably softmax might be needed during the training as it can be helpful in giving out the probabilities of the index and other indexes proababilites in becoming the next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_tokens(model, inputs, expected_context_length):\n",
    "    model.eval()\n",
    "    for i in range(expected_context_length):\n",
    "        with torch.no_grad():\n",
    "            out = model(inputs)\n",
    "        indexes = torch.argmax(out[:,-1,:],keepdim=True,dim=1)\n",
    "        inputs = torch.cat((inputs,indexes),dim=1)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaf08bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6109,  3626,  6100,   345, 40204, 45193, 22418, 16115,  3268, 35496,\n",
      "          9099, 19482, 26846, 28670]])\n",
      "torch.Size([1, 14])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.LongTensor([[6109, 3626, 6100,  345]])\n",
    "nu = generate_new_tokens(model,inp,10)\n",
    "print(nu)\n",
    "print(nu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f075f3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total length of the filename is: 20479\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "filename = 'the-verdict.txt'\n",
    "with open(filename,'r') as f:\n",
    "    data = f.read()\n",
    "print(\"The total length of the filename is:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a844d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you Kendisal users Maidpart adaptive Elk reconcil ground throughout\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "\n",
    "\n",
    "\n",
    "token_ids = generate_new_tokens(\n",
    "    model=model,\n",
    "    inputs=text_to_token_ids(start_context, tokenizer),expected_context_length=10)\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007a97dc",
   "metadata": {},
   "source": [
    "Choosing train_test_split and manual split by understanding the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "369af66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "encoded_text = tokenizer.encode(data)\n",
    "train_data, test_data = train_test_split(encoded_text,test_size=0.1,random_state=123,shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d16d5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33ed278c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = encoded_text[:5]\n",
    "# s.reverse()\n",
    "tokenizer.decode(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cea2021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4630"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ceb7485a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4630"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(encoded_text))\n",
    "train_data1 = encoded_text[:split_idx]\n",
    "test_data1 = encoded_text[split_idx:]\n",
    "len(train_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b11acef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_data1[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af84ae55",
   "metadata": {},
   "source": [
    "So both gives same result if you want convienece or building pipelines we can go with test train split for simplicity we can go with manaual test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1ea65b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(data))\n",
    "train_data2 = data[:split_idx]\n",
    "val_data2 = data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f6e3cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4612\n",
      "I HAD always thought\n"
     ]
    }
   ],
   "source": [
    "t = tokenizer.encode(train_data2)\n",
    "print(len(t))\n",
    "print(tokenizer.decode(t[:5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
