# Building-GPT-2-for-chatbot

ÔÅÆThis project focuses on building a custom LLM similar to that of GPT-2 focusing on conversational chatbot. 
Implemented Byte-wise tokeniser with positional and token embedding coded a multi-head attention mechanism forming a transformer architecture and finetuned for chatbots and classification tasks
